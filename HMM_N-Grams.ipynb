{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#import h5py\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas\n",
    "import pymorphy2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем входные данные\n",
    "Наши входные данные это новостной массив за 2014 год."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path  = './data/' \n",
    "input_file = input_path + 'news_src.txt' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-граммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим таблицу вероятности встречаемости n-gramm для нашей модели <br>\n",
    "Оценим вероятность слов в фразе: <br>\n",
    " *Президент США Барак Обама решил сняться в телепередаче с Беар Гриллсом.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimated_phrase = ['президент', 'сша', 'барак', 'обама', 'решить', 'сняться', 'в', 'телепередача', 'с', 'беар', 'гриллсом']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigramm\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# получить набор unigramm согласно заданным параметрам\n",
    "# - считаем частоты слов в датасете\n",
    "# \n",
    "#\n",
    "def get_unigramm_set(input_file, max_row_count=1e+5):\n",
    "    unigramm_set = {}\n",
    "    with open(input_file) as ifile:\n",
    "        # итерация по всем документам\n",
    "        for i, line in enumerate(ifile):\n",
    "            parts = line.strip().split('\\t')\n",
    "            url = parts[0] # первое поле урл\n",
    "            # пропускаем пустые документы\n",
    "            if len(parts) <=1 : continue\n",
    "            # \n",
    "            for j, sentens in enumerate(parts[1:]):\n",
    "                sent = sentens.strip().split()\n",
    "                slen = len(sent)\n",
    "                if slen == 0: continue\n",
    "                ar = []\n",
    "                for iw, w in enumerate(sent):\n",
    "                    \n",
    "                    if w not in unigramm_set:\n",
    "                        unigramm_set[w] = 0\n",
    "                    unigramm_set[w] = unigramm_set[w] + 1 \n",
    "\n",
    "            sys.stderr.write('\\r'+str(i) + \" total unigram: \" + str(len(unigramm_set)))\n",
    "            if i == max_row_count:\n",
    "                break\n",
    "    return unigramm_set               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Получаем список униграмм "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 total unigram: 248208"
     ]
    }
   ],
   "source": [
    "unigramm_set = get_unigramm_set(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_unigramms = 0\n",
    "for v in unigramm_set.values():\n",
    "    total_unigramms = total_unigramms + v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Считаем вероятность появления каждой униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unigramm_probability_for(unigramm_set, total, phrase):\n",
    "    sorted_inigramms = sorted(unigramm_set.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    n_top_words = {}\n",
    "    for word in phrase:\n",
    "        n_top_words[word] = (-1, 0)\n",
    "        for i, uni in enumerate(sorted_inigramms):\n",
    "             if uni[0] in n_top_words:\n",
    "                n_top_words[uni[0]] = (i, uni[1] / float(total) )\n",
    "    return  n_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_probs = calculate_unigramm_probability_for(unigramm_set, total_unigramms, estimated_phrase )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_panda_table(probs):\n",
    "    top_20_values = [[], []]\n",
    "    for i, k in enumerate(estimated_phrase):\n",
    "        top_20_values[0].append(int(probs[k][0]))\n",
    "        top_20_values[1].append(probs[k][1])\n",
    "    ###        \n",
    "    # Делаем таблицу pandas\n",
    "    ###\n",
    "    dt = estimated_phrase\n",
    "    values = np.asarray(top_20_values)\n",
    "    values = values.reshape(2,11)\n",
    "    index = [\"num\", \"prob\"]\n",
    "\n",
    "    return pandas.DataFrame(values, index=index, columns=dt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выводим распределение для каждой униграммы в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>президент</th>\n",
       "      <th>сша</th>\n",
       "      <th>барак</th>\n",
       "      <th>обама</th>\n",
       "      <th>решить</th>\n",
       "      <th>сняться</th>\n",
       "      <th>в</th>\n",
       "      <th>телепередача</th>\n",
       "      <th>с</th>\n",
       "      <th>беар</th>\n",
       "      <th>гриллсом</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>3395.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>4657.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15613.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14581.000000</td>\n",
       "      <td>21467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob</th>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.043321</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      президент        сша        барак        обама      решить      сняться  \\\n",
       "num   76.000000  116.00000  3395.000000  1799.000000  328.000000  4657.000000   \n",
       "prob   0.001167    0.00084     0.000037     0.000081    0.000395     0.000024   \n",
       "\n",
       "             в  телепередача         с          беар      гриллсом  \n",
       "num   0.000000  15613.000000  3.000000  14581.000000  21467.000000  \n",
       "prob  0.043321      0.000004  0.011905      0.000004      0.000002  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_panda_table(unigram_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Самые вероятные униграммы -  самые частотные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в 0.0433\n",
      "и 0.0245\n",
      "на 0.0194\n",
      "с 0.0119\n",
      "по 0.0098\n",
      "что 0.0094\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(sorted(unigramm_set.items(), key=operator.itemgetter(1), reverse=True)):\n",
    "    print  k[0]  + ' %0.4f'%(k[1] / float(total_unigramms))\n",
    "    if i == 5: break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigramm\n",
    "====\n",
    "Оценим ту же самую фразу с точки зрения биграмной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем биграммы с их частотой <br>\n",
    "bigramm_set = {{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_bigram_set(input_file, max_row_count=1e+5):\n",
    "    bigramm_set = {}\n",
    "    with open(input_file) as ifile:\n",
    "        # итерация по всем документам\n",
    "        for i, line in enumerate(ifile):\n",
    "            parts = line.strip().split('\\t')\n",
    "            url = parts[0] # первое поле урл\n",
    "            # пропускаем пустые документы\n",
    "            if len(parts) <=1 : continue\n",
    "            # \n",
    "            for j, sentens in enumerate(parts[1:]):\n",
    "                sent = sentens.strip().split()\n",
    "                slen = len(sent)\n",
    "                if slen == 0: continue\n",
    "                ar = []\n",
    "                for iw, w in enumerate(sent):\n",
    "                    if iw + 1 < slen:\n",
    "                        #bigram = w + ' ' + sent[iw+1]\n",
    "                        if w not in bigramm_set:\n",
    "                            bigramm_set[w] = {}\n",
    "                        if sent[iw+1] not in bigramm_set[w]:\n",
    "                            bigramm_set[w][sent[iw+1]] = 0\n",
    "                        bigramm_set[w][sent[iw+1]] = bigramm_set[w][sent[iw+1]] + 1 \n",
    "\n",
    "            sys.stderr.write('\\r'+str(i) + \" total bigram: \" + str(len(bigramm_set)))\n",
    "            if i == max_row_count:\n",
    "                break\n",
    "    return bigramm_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 total bigram: 228964"
     ]
    }
   ],
   "source": [
    "bigramm_set = get_bigram_set(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_bigramms = 0\n",
    "for v1 in bigramm_set.keys():\n",
    "    for v2 in bigramm_set[v1].values():\n",
    "        total_bigramms = total_bigramms + v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Рассчитываем биграмную вероятность для нашей фразы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_bigramm_probability_for(bigramm_set, unigramm_set, phrase):\n",
    "    #sorted_gramms = sorted(bigramm_set.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    n_top_words = {}\n",
    "    plen = len(phrase)\n",
    "    for iw in range(0, plen-1):\n",
    "        word1 = phrase[iw]\n",
    "        word2 = phrase[iw+1]\n",
    "        bigramm = word1 + ' ' + word2\n",
    "        n_top_words[bigramm] = (-1, 0)\n",
    "        if word1 in bigramm_set:\n",
    "            sorted_gramms = sorted(bigramm_set[word1].items(), key=operator.itemgetter(1), reverse=True)\n",
    "            for i, uni in enumerate(sorted_gramms):\n",
    "                 if word1 + ' ' + uni[0] in n_top_words:\n",
    "                    n_top_words[bigramm] = (i, uni[1] / float(unigramm_set[word1]) )\n",
    "    return  n_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_probs = calculate_bigramm_probability_for(bigramm_set, unigramm_set, estimated_phrase )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob_panda_tableII(probs):\n",
    "    top_20_values = [[], []]\n",
    "    phrase_dt = []\n",
    "    plen = len(estimated_phrase)\n",
    "    for iw in range(0, plen-1):\n",
    "        bigramm = estimated_phrase[iw] + ' ' + estimated_phrase[iw+1]\n",
    "        phrase_dt.append(bigramm)\n",
    "        top_20_values[0].append(int(probs[bigramm][0]))\n",
    "        top_20_values[1].append(probs[bigramm][1])\n",
    "    ###        \n",
    "    # Делаем таблицу pandas\n",
    "    ###\n",
    "    dt = phrase_dt\n",
    "    values = np.asarray(top_20_values)\n",
    "    values = values.reshape(2,10)\n",
    "    index = [\"num\", \"prob\"]\n",
    "\n",
    "    return pandas.DataFrame(values, index=index, columns=dt)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выводим таблицу вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>президент сша</th>\n",
       "      <th>сша барак</th>\n",
       "      <th>барак обама</th>\n",
       "      <th>обама решить</th>\n",
       "      <th>решить сняться</th>\n",
       "      <th>сняться в</th>\n",
       "      <th>в телепередача</th>\n",
       "      <th>телепередача с</th>\n",
       "      <th>с беар</th>\n",
       "      <th>беар гриллсом</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3735.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2105.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob</th>\n",
       "      <td>0.034506</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.931526</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.451685</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.316456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      президент сша  сша барак  барак обама  обама решить  решить сняться  \\\n",
       "num        4.000000   2.000000     0.000000     66.000000      264.000000   \n",
       "prob       0.034506   0.022638     0.931526      0.002606        0.000671   \n",
       "\n",
       "      сняться в  в телепередача  телепередача с       с беар  беар гриллсом  \n",
       "num    0.000000     3735.000000       16.000000  2105.000000       1.000000  \n",
       "prob   0.451685        0.000018        0.014085     0.000062       0.316456  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_panda_tableII(bigram_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Можем вывести топ слов, которые предшествуют данной биграмме. Например, для биграммы 'презедент США', наиболее вероятная биграмма 'презедент россии'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сша  и 0.0713204691638\n",
      "сша  в 0.0707529322739\n",
      "сша  барак 0.0226384159415\n",
      "сша  по 0.0218817000883\n",
      "сша  на 0.0180981208223\n"
     ]
    }
   ],
   "source": [
    "sorted_gramms = sorted(bigramm_set['сша'].items(), key=operator.itemgetter(1), reverse=True)\n",
    "for  uni in sorted_gramms[0:5]:\n",
    "     print 'сша  ' + uni[0] + ' ' + str(uni[1] /  float(unigramm_set['сша'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество модели улучшилось, например, мы точно знаем, что после слова барак вероятнее всего стоит слово обама. Но к слову сша плохо подходит барак. Если сделаем триграмную модель, то получим большую вероятность того, что за презедент сша должен следовать барак** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-gramm\n",
    "\n",
    "Самостоятельно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сглаживание\n",
    "\n",
    "Реализовать сглаживание Лапласа на 3-грамной модели самостоятельно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "Марковские цепи\n",
    "===\n",
    "Оценим вероятность фразы “Президент США Барак Обама решил сняться в телепередаче с Беар Гриллсом.” через марковскую цепь. <br>\n",
    "Начальное состояние  - нахождение слова в начале предложения: pi <br>\n",
    "Слово - состояние марковской цепи: s <br>\n",
    "Вероятности перехода между словами - наши вероятностные события: x.\n",
    "<br>\n",
    "<br>\n",
    "**Рассчитаем вероятности событий**\n",
    "<br>\n",
    "pi - начальные вероятности \n",
    "<br>\n",
    "state_transitions - вероятности перехода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сначала получим статистику по взаимной встречаемости слов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_markov_transition_stats(input_file, max_row_count=1e+5):\n",
    "    state_transitions = {}\n",
    "    pi = {}\n",
    "    count_first_pos = 0\n",
    "    with open(input_file) as ifile:\n",
    "        # итерация по всем документам\n",
    "        for i, line in enumerate(ifile):\n",
    "            parts = line.strip().split('\\t')\n",
    "            url = parts[0] # первое поле урл\n",
    "            # пропускаем пустые документы\n",
    "            if len(parts) <=1 : continue\n",
    "            # \n",
    "            for j, sentens in enumerate(parts[1:]):\n",
    "                sent = sentens.strip().split()\n",
    "                slen = len(sent)\n",
    "                if slen == 0: continue\n",
    "                ar = []\n",
    "                for iw, w in enumerate(sent):\n",
    "                    if iw == 0:\n",
    "                        count_first_pos = count_first_pos + 1\n",
    "                        if w not in pi:\n",
    "                            pi [w]  = 0\n",
    "                        pi[w] = pi[w] + 1\n",
    "                    if iw + 1 < slen:\n",
    "                        #bigram = w + ' ' + sent[iw+1]\n",
    "                        if w not in state_transitions:\n",
    "                            state_transitions[w] = {}\n",
    "                        if sent[iw+1] not in state_transitions[w]:\n",
    "                            state_transitions[w][sent[iw+1]] = 0\n",
    "                        state_transitions[w][sent[iw+1]] = state_transitions[w][sent[iw+1]] + 1 \n",
    "\n",
    "            sys.stderr.write('\\r'+str(i) + \" total bigram: \" + str(len(state_transitions)))\n",
    "            if i == max_row_count:\n",
    "                break\n",
    "    return state_transitions, pi, count_first_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 total bigram: 228964"
     ]
    }
   ],
   "source": [
    "state_transitions_stats, pi_stats, count_sent = get_markov_transition_stats(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь саму вероятность перехдов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_transition_probability_for(state_transitions_stats, pi_stats, unigramm_set, count_sent):\n",
    "    #sorted_gramms = sorted(bigramm_set.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    transition_probs = {}\n",
    "    pi_probs = {}\n",
    "    for word in pi_stats.keys():\n",
    "        pi_probs[word] = pi_stats[word] / float(count_sent) \n",
    "        \n",
    "    for word1 in state_transitions_stats.keys():\n",
    "        if word1 not in transition_probs:\n",
    "            transition_probs[word1] = {}\n",
    "        for word2 in state_transitions_stats[word1]:\n",
    "            if word2 not in transition_probs[word1]:\n",
    "                transition_probs[word1][word2] = 0            \n",
    "            transition_probs[word1][word2] = state_transitions_stats[word1][word2] / float(unigramm_set[word1])\n",
    "    return  transition_probs, pi_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transition_probs, pi_probs = calculate_transition_probability_for(state_transitions_stats, pi_stats, unigramm_set, count_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводим вероятности перехода в виде таблички и считаем полную вероятность фразы**\n",
    "Используем логарифм для того, что бы от умножения перейти к сложению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_prob_panda_table(state_probs, pi, estimated_phrase):\n",
    "    top_20_values = []\n",
    "    phrase_dt = []\n",
    "    plen = len(estimated_phrase)\n",
    "    top_20_values.append(pi[estimated_phrase[0]])\n",
    "    phrase_dt.append('pi (' + estimated_phrase[0] + ') ')\n",
    "    \n",
    "   \n",
    "    for iw in range(0, plen-1):\n",
    "        bigramm = 'p_s(' + estimated_phrase[iw] + '->' + estimated_phrase[iw+1] + ')'\n",
    "        phrase_dt.append(bigramm)\n",
    "        # есть вероятность\n",
    "        if estimated_phrase[iw] in state_probs and estimated_phrase[iw+1]  in state_probs[estimated_phrase[iw]]:\n",
    "            top_20_values.append(state_probs[estimated_phrase[iw]][estimated_phrase[iw+1]])\n",
    "        else :\n",
    "            top_20_values.append(1/float(len(state_probs)))\n",
    "    \n",
    "    result_prob = 1.\n",
    "    log_prob = 0\n",
    "    for prob in top_20_values:\n",
    "        result_prob = result_prob * prob\n",
    "        log_prob    = log_prob + math.log(prob) \n",
    "    \n",
    "    top_20_values.append(result_prob)\n",
    "    top_20_values.append(log_prob)\n",
    "    phrase_dt.append('p(X1, ..., Xn)')\n",
    "    phrase_dt.append('log(p(X1, ..., Xn))')\n",
    "    ###        \n",
    "    # Делаем таблицу pandas\n",
    "    ###\n",
    "    dt = phrase_dt\n",
    "    values = np.asarray(top_20_values)\n",
    "    values = values.reshape(1,13)\n",
    "    index = [\"probs\"]\n",
    "\n",
    "    return pandas.DataFrame(values, index=index, columns=dt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pi (президент)</th>\n",
       "      <th>p_s(президент-&gt;сша)</th>\n",
       "      <th>p_s(сша-&gt;барак)</th>\n",
       "      <th>p_s(барак-&gt;обама)</th>\n",
       "      <th>p_s(обама-&gt;решить)</th>\n",
       "      <th>p_s(решить-&gt;сняться)</th>\n",
       "      <th>p_s(сняться-&gt;в)</th>\n",
       "      <th>p_s(в-&gt;телепередача)</th>\n",
       "      <th>p_s(телепередача-&gt;с)</th>\n",
       "      <th>p_s(с-&gt;беар)</th>\n",
       "      <th>p_s(беар-&gt;гриллсом)</th>\n",
       "      <th>p(X1, ..., Xn)</th>\n",
       "      <th>log(p(X1, ..., Xn))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>probs</th>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.034506</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.931526</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.451685</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>6.518518e-24</td>\n",
       "      <td>-53.387395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pi (президент)   p_s(президент->сша)  p_s(сша->барак)  \\\n",
       "probs         0.002227             0.034506         0.022638   \n",
       "\n",
       "       p_s(барак->обама)  p_s(обама->решить)  p_s(решить->сняться)  \\\n",
       "probs           0.931526            0.002606              0.000671   \n",
       "\n",
       "       p_s(сняться->в)  p_s(в->телепередача)  p_s(телепередача->с)  \\\n",
       "probs         0.451685              0.000018              0.014085   \n",
       "\n",
       "       p_s(с->беар)  p_s(беар->гриллсом)  p(X1, ..., Xn)  log(p(X1, ..., Xn))  \n",
       "probs      0.000062             0.316456    6.518518e-24           -53.387395  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trans_prob_panda_table(transition_probs, pi_probs, estimated_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посчитаем вероятность другой фразы заменив в базовой фразе одно слово**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_estimated_phrase = ['президент', 'китая', 'барак', 'обама', 'решить', 'сняться', 'в', 'телепередача', 'с', 'беар', 'гриллсом']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pi (президент)</th>\n",
       "      <th>p_s(президент-&gt;китая)</th>\n",
       "      <th>p_s(китая-&gt;барак)</th>\n",
       "      <th>p_s(барак-&gt;обама)</th>\n",
       "      <th>p_s(обама-&gt;решить)</th>\n",
       "      <th>p_s(решить-&gt;сняться)</th>\n",
       "      <th>p_s(сняться-&gt;в)</th>\n",
       "      <th>p_s(в-&gt;телепередача)</th>\n",
       "      <th>p_s(телепередача-&gt;с)</th>\n",
       "      <th>p_s(с-&gt;беар)</th>\n",
       "      <th>p_s(беар-&gt;гриллсом)</th>\n",
       "      <th>p(X1, ..., Xn)</th>\n",
       "      <th>log(p(X1, ..., Xn))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>probs</th>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.931526</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.451685</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>1.591735e-31</td>\n",
       "      <td>-70.915313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pi (президент)   p_s(президент->китая)  p_s(китая->барак)  \\\n",
       "probs         0.002227               0.000004           0.000004   \n",
       "\n",
       "       p_s(барак->обама)  p_s(обама->решить)  p_s(решить->сняться)  \\\n",
       "probs           0.931526            0.002606              0.000671   \n",
       "\n",
       "       p_s(сняться->в)  p_s(в->телепередача)  p_s(телепередача->с)  \\\n",
       "probs         0.451685              0.000018              0.014085   \n",
       "\n",
       "       p_s(с->беар)  p_s(беар->гриллсом)  p(X1, ..., Xn)  log(p(X1, ..., Xn))  \n",
       "probs      0.000062             0.316456    1.591735e-31           -70.915313  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_trans_prob_panda_table(transition_probs, pi_probs, false_estimated_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Теперь мы можем сравнивать вероятности для двух фраз и таким образом оценивать естесвенность данной языковой модели. Например можно оценить авторство, какому источнику принадлежит данный текст. Классификацию источников можно сделать самостоятельно*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Скрытые Марковские Модели\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Три задачи, которые нужно решить\n",
    "1. Определить насколько наши наблюдения соответсвуют модели.\n",
    "2. Выстроить последовательность согласно нашим наблюдениям.\n",
    "3. Подобрать параметры модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
